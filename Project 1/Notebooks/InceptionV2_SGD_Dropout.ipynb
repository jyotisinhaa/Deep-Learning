{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_SGD_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyOazSpWztcP"
      },
      "source": [
        "<h3><b> Importing Library</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNYk17cCS0lA"
      },
      "source": [
        "# Importing Libraries\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import math \n",
        "import cv2 \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import regularizers\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D,Flatten"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3XLVJepz2DV"
      },
      "source": [
        "<h3><b> Importing Dataset</b><h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuhv097NYrfu",
        "outputId": "b23249f7-4b51-403f-f3d0-8b69e08e9692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2yAtEqs0DTO"
      },
      "source": [
        "<h3><b> Preprocessing of the dataset</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1xMv3g8Yxl4"
      },
      "source": [
        "# Normalize the dataset\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUcSJ9bPY4Yu"
      },
      "source": [
        "#Converting the testing and training dataset into float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UfXOG68Y741",
        "outputId": "9ac4784a-ed78-4d71-ac5d-807f955bcf6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert training and test labels to one hot matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_test = keras.utils.to_categorical(y_test, 100)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtqhVwFs0_yO"
      },
      "source": [
        "<h3><b> Model Architecure</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLLcjHtgid1I"
      },
      "source": [
        "def inception_moduleA(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_3x3a,\n",
        "                      filters_3x3b,\n",
        "                  \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='elu')(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3a = Conv2D(filters_3x3a, (3, 3), padding='same', activation='elu')(conv_5x5)\n",
        "    conv_3x3b = Conv2D(filters_3x3b, (3, 3), padding='same', activation='elu')(conv_3x3a)\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_3x3a, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def inception_moduleB(x,\n",
        "                     filters_1x1modb,\n",
        "                     filters_3x3_reducemodb,\n",
        "                     filters_1x3modb,\n",
        "                     filters_3x1modb,\n",
        "                     filters_5x5_reducemodb,\n",
        "                     filters_1x3amodb,\n",
        "                      filters_3x1amodb,\n",
        "                     filters_1x3bmodb,\n",
        "                      filters_3x1bmodb,\n",
        "                  \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1modb = Conv2D(filters_1x1modb, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3modb = Conv2D(filters_3x3_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3modb = Conv2D(filters_1x3modb, (1, 3), padding='same', activation='elu')(conv_3x3modb)\n",
        "    conv_3x1modb = Conv2D(filters_3x1modb, (3, 1), padding='same', activation='elu')(conv_1x3modb)\n",
        "\n",
        "    conv_5x5modb = Conv2D(filters_5x5_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3amodb = Conv2D(filters_1x3amodb, (1, 3), padding='same', activation='elu')(conv_5x5modb)\n",
        "    conv_3x1amodb = Conv2D(filters_3x1amodb, (3, 1), padding='same', activation='elu')(conv_1x3amodb)\n",
        "    conv_1x3bmodb = Conv2D(filters_1x3bmodb, (1, 3), padding='same', activation='elu')(conv_3x1amodb)\n",
        "    conv_3x1bmodb = Conv2D(filters_3x1bmodb, (3, 1), padding='same', activation='elu')(conv_1x3bmodb)\n",
        "\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1modb, conv_3x1modb, conv_3x1bmodb, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def inception_moduleC(x,\n",
        "                     filters_1x1modc,\n",
        "                      filters_3x3_reducemodc,\n",
        "                     filters_1x3modc,\n",
        "                      filters_3x1modc,\n",
        "                     filters_5x5_reducemodc,\n",
        "                        filters_3x3amodc,\n",
        "                      filters_1x3amodc,\n",
        "                       filters_3x1amodc,\n",
        "                      \n",
        "                   \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1modc = Conv2D(filters_1x1modc, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3modc = Conv2D(filters_3x3_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3modc = Conv2D(filters_1x3modc, (1, 3), padding='same', activation='elu')(conv_3x3modc)\n",
        "    conv_3x1modc = Conv2D(filters_3x1modc, (3, 1), padding='same', activation='elu')(conv_1x3modc)\n",
        "\n",
        "    conv_5x5modc = Conv2D(filters_5x5_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3amodc = Conv2D(filters_3x3amodc, (1, 1), padding='same', activation='elu')(conv_5x5modc)\n",
        "\n",
        "    conv_1x3amodc = Conv2D(filters_1x3amodc, (1, 3), padding='same', activation='elu')(conv_3x3amodc)\n",
        "    conv_3x1amodc = Conv2D(filters_3x1amodc, (3, 1), padding='same', activation='elu')(conv_1x3amodc)\n",
        "\n",
        "\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1modc,conv_1x3modc, conv_3x1modc, conv_1x3amodc,conv_3x1amodc, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br3rOWOzHxJJ"
      },
      "source": [
        "input_layer = Input(shape=(32, 32, 3))\n",
        "\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_1a_3x3/2')(input_layer)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_2a_3x3/1')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_3a_3x3/1')(x)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_4a_3x3/1')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_5a_3x3/2')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_6a_3x3/1')(x)\n",
        "\n",
        "x = inception_moduleA(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_3x3a=32,\n",
        "                     filters_3x3b=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3a')\n",
        "x = inception_moduleA(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_3x3a=32,\n",
        "                     filters_3x3b=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3aa')\n",
        "\n",
        "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
        "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
        "# x = inception_moduleA(x,\n",
        "#                      filters_1x1=64,\n",
        "#                      filters_3x3_reduce=96,\n",
        "#                      filters_3x3=128,\n",
        "#                      filters_5x5_reduce=16,\n",
        "#                      filters_3x3a=32,\n",
        "#                      filters_3x3b=32,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_3aaa')\n",
        "\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                   filters_pool_proj=32,\n",
        "                     name='inception_4a')\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_4aa')\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                      filters_pool_proj=32,\n",
        "             \n",
        "                     name='inception_4aaa')\n",
        "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
        "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
        "# x = inception_moduleB(x,\n",
        "#                      filters_1x1modb=64,\n",
        "#                      filters_3x3_reducemodb=96,\n",
        "#                      filters_1x3modb=128,\n",
        "#                      filters_3x1modb=128,\n",
        "#                      filters_5x5_reducemodb=16,\n",
        "#                      filters_1x3amodb=128,\n",
        "#                      filters_3x1amodb=128,\n",
        "#                      filters_1x3bmodb=128,\n",
        "#                      filters_3x1bmodb=128,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_4aaaa')\n",
        "# x = inception_moduleB(x,\n",
        "#                      filters_1x1modb=64,\n",
        "#                      filters_3x3_reducemodb=96,\n",
        "#                      filters_1x3modb=128,\n",
        "#                      filters_3x1modb=128,\n",
        "#                      filters_5x5_reducemodb=16,\n",
        "#                      filters_1x3amodb=128,\n",
        "#                      filters_3x1amodb=128,\n",
        "#                      filters_1x3bmodb=128,\n",
        "#                      filters_3x1bmodb=128,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_4aaaaa')\n",
        "\n",
        "x = inception_moduleC(x,\n",
        "                     filters_1x1modc=64,\n",
        "                     filters_3x3_reducemodc=96,\n",
        "                     filters_1x3modc=128,\n",
        "                     filters_3x1modc=128,\n",
        "                     filters_5x5_reducemodc=16,\n",
        "                     filters_3x3amodc=128,\n",
        "                     filters_1x3amodc=128,\n",
        "                     filters_3x1amodc=128,\n",
        "                     filters_pool_proj=32,\n",
        "                    \n",
        "                     name='inception_5a')\n",
        "x = inception_moduleC(x,\n",
        "                     filters_1x1modc=64,\n",
        "                     filters_3x3_reducemodc=96,\n",
        "                     filters_1x3modc=128,\n",
        "                     filters_3x1modc=128,\n",
        "                     filters_5x5_reducemodc=16,\n",
        "                     filters_3x3amodc=128,\n",
        "                     filters_1x3amodc=128,\n",
        "                     filters_3x1amodc=128,\n",
        "                     filters_pool_proj=32,\n",
        "             \n",
        "                     name='inception_5aa')\n",
        "\n",
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Flatten()(x)\n",
        "output = Dense(100, activation='softmax', name='output')(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GWOmOi_qTCS"
      },
      "source": [
        "model = Model(input_layer,  output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok_nFUWbFuwg",
        "outputId": "94f7fc28-f2bc-4bda-e241-4942a45d9b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1a_3x3/2 (Conv2D)          (None, 16, 16, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       conv_1a_3x3/2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_3a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 8, 8, 64)     0           conv_3a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_4a_3x3/1 (Conv2D)          (None, 8, 8, 64)     36928       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv_5a_3x3/2 (Conv2D)          (None, 4, 4, 64)     36928       conv_4a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_6a_3x3/1 (Conv2D)          (None, 4, 4, 64)     36928       conv_5a_3x3/2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 4, 4, 96)     6240        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 16)     1040        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 4, 4, 64)     0           conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 4, 4, 64)     4160        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 4, 4, 128)    110720      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 4, 4, 32)     4640        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 4, 4, 32)     2080        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 4, 4, 256)    0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 4, 4, 96)     24672       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 16)     4112        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 256)    0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 64)     16448       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 128)    110720      conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 4, 4, 32)     8224        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3aa (Concatenate)     (None, 4, 4, 256)    0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 16)     4112        inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 96)     24672       inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 64)     16448       inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 32)     8224        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 4, 4, 352)    0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 16)     5648        inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 96)     33888       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 64)     22592       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4aa (Concatenate)     (None, 4, 4, 352)    0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 16)     5648        inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 96)     33888       inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 64)     22592       inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4aaa (Concatenate)    (None, 4, 4, 352)    0           conv2d_34[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 16)     5648        inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 96)     33888       inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 128)    2176        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 64)     22592       inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 4, 4, 608)    0           conv2d_44[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 4, 4, 16)     9744        inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 96)     58464       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 4, 4, 128)    2176        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 608)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 64)     38976       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 4, 4, 32)     19488       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5aa (Concatenate)     (None, 4, 4, 608)    0           conv2d_53[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 608)          0           inception_5aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 608)          0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 608)          0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 100)          60900       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,040,596\n",
            "Trainable params: 2,040,596\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-jkzpVu1SSF"
      },
      "source": [
        "<h3><b> Model Compile</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPd9gc_sBziE"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "lr_decay = 1e-6\n",
        "#optimization details\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_rq-y4K1rgo",
        "outputId": "ec7b6c3a-f7d1-4dd6-d90f-1ee8d96f7432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create Checkpoint and Early Stopping\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"InceptionV2_SGD_Dropout.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HogWDFCh1ZxX"
      },
      "source": [
        "<h3><b> Train the Model</b><h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxkeVrtvF0Ok",
        "outputId": "d6ec8f2c-2279-4cfa-fb8d-707442d62e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=150, batch_size=256, callbacks=[checkpoint,early])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "  2/196 [..............................] - ETA: 14s - loss: 4.6050 - accuracy: 0.0059WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0509s vs `on_train_batch_end` time: 0.0958s). Check your callbacks.\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.6033 - accuracy: 0.0128\n",
            "Epoch 00001: val_loss improved from inf to 4.60000, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 32s 162ms/step - loss: 4.6033 - accuracy: 0.0128 - val_loss: 4.6000 - val_accuracy: 0.0147\n",
            "Epoch 2/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.5946 - accuracy: 0.0207\n",
            "Epoch 00002: val_loss improved from 4.60000 to 4.58516, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 4.5946 - accuracy: 0.0207 - val_loss: 4.5852 - val_accuracy: 0.0282\n",
            "Epoch 3/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.5544 - accuracy: 0.0237\n",
            "Epoch 00003: val_loss improved from 4.58516 to 4.50191, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.5544 - accuracy: 0.0237 - val_loss: 4.5019 - val_accuracy: 0.0231\n",
            "Epoch 4/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.4637 - accuracy: 0.0237\n",
            "Epoch 00004: val_loss improved from 4.50191 to 4.41621, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.4637 - accuracy: 0.0237 - val_loss: 4.4162 - val_accuracy: 0.0258\n",
            "Epoch 5/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.3865 - accuracy: 0.0298\n",
            "Epoch 00005: val_loss improved from 4.41621 to 4.32274, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.3865 - accuracy: 0.0298 - val_loss: 4.3227 - val_accuracy: 0.0318\n",
            "Epoch 6/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.3077 - accuracy: 0.0358\n",
            "Epoch 00006: val_loss improved from 4.32274 to 4.25558, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.3077 - accuracy: 0.0358 - val_loss: 4.2556 - val_accuracy: 0.0422\n",
            "Epoch 7/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.2480 - accuracy: 0.0415\n",
            "Epoch 00007: val_loss improved from 4.25558 to 4.20082, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.2480 - accuracy: 0.0415 - val_loss: 4.2008 - val_accuracy: 0.0488\n",
            "Epoch 8/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.1954 - accuracy: 0.0461\n",
            "Epoch 00008: val_loss improved from 4.20082 to 4.14350, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.1954 - accuracy: 0.0461 - val_loss: 4.1435 - val_accuracy: 0.0591\n",
            "Epoch 9/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.1428 - accuracy: 0.0533\n",
            "Epoch 00009: val_loss improved from 4.14350 to 4.07694, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.1428 - accuracy: 0.0533 - val_loss: 4.0769 - val_accuracy: 0.0719\n",
            "Epoch 10/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.0867 - accuracy: 0.0604\n",
            "Epoch 00010: val_loss improved from 4.07694 to 4.02772, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.0867 - accuracy: 0.0604 - val_loss: 4.0277 - val_accuracy: 0.0774\n",
            "Epoch 11/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.0319 - accuracy: 0.0665\n",
            "Epoch 00011: val_loss improved from 4.02772 to 4.00160, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 4.0319 - accuracy: 0.0665 - val_loss: 4.0016 - val_accuracy: 0.0808\n",
            "Epoch 12/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.9868 - accuracy: 0.0717\n",
            "Epoch 00012: val_loss improved from 4.00160 to 3.91168, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.9868 - accuracy: 0.0717 - val_loss: 3.9117 - val_accuracy: 0.0946\n",
            "Epoch 13/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.9514 - accuracy: 0.0789\n",
            "Epoch 00013: val_loss improved from 3.91168 to 3.89298, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.9514 - accuracy: 0.0789 - val_loss: 3.8930 - val_accuracy: 0.0951\n",
            "Epoch 14/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.9144 - accuracy: 0.0841\n",
            "Epoch 00014: val_loss improved from 3.89298 to 3.85910, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.9144 - accuracy: 0.0841 - val_loss: 3.8591 - val_accuracy: 0.1068\n",
            "Epoch 15/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.8737 - accuracy: 0.0899\n",
            "Epoch 00015: val_loss improved from 3.85910 to 3.79818, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.8737 - accuracy: 0.0899 - val_loss: 3.7982 - val_accuracy: 0.1120\n",
            "Epoch 16/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.8225 - accuracy: 0.0982\n",
            "Epoch 00016: val_loss improved from 3.79818 to 3.74949, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.8225 - accuracy: 0.0982 - val_loss: 3.7495 - val_accuracy: 0.1215\n",
            "Epoch 17/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.7717 - accuracy: 0.1054\n",
            "Epoch 00017: val_loss improved from 3.74949 to 3.71179, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.7717 - accuracy: 0.1054 - val_loss: 3.7118 - val_accuracy: 0.1277\n",
            "Epoch 18/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.7224 - accuracy: 0.1128\n",
            "Epoch 00018: val_loss improved from 3.71179 to 3.64989, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.7224 - accuracy: 0.1128 - val_loss: 3.6499 - val_accuracy: 0.1399\n",
            "Epoch 19/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.6740 - accuracy: 0.1186\n",
            "Epoch 00019: val_loss improved from 3.64989 to 3.61690, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.6740 - accuracy: 0.1186 - val_loss: 3.6169 - val_accuracy: 0.1394\n",
            "Epoch 20/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.6308 - accuracy: 0.1260\n",
            "Epoch 00020: val_loss improved from 3.61690 to 3.56187, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.6308 - accuracy: 0.1260 - val_loss: 3.5619 - val_accuracy: 0.1493\n",
            "Epoch 21/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.5858 - accuracy: 0.1337\n",
            "Epoch 00021: val_loss improved from 3.56187 to 3.50903, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.5858 - accuracy: 0.1337 - val_loss: 3.5090 - val_accuracy: 0.1620\n",
            "Epoch 22/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.5389 - accuracy: 0.1409\n",
            "Epoch 00022: val_loss did not improve from 3.50903\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.5389 - accuracy: 0.1409 - val_loss: 3.5524 - val_accuracy: 0.1496\n",
            "Epoch 23/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4937 - accuracy: 0.1467\n",
            "Epoch 00023: val_loss improved from 3.50903 to 3.40860, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 3.4937 - accuracy: 0.1467 - val_loss: 3.4086 - val_accuracy: 0.1785\n",
            "Epoch 24/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4397 - accuracy: 0.1572\n",
            "Epoch 00024: val_loss improved from 3.40860 to 3.36882, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.4397 - accuracy: 0.1572 - val_loss: 3.3688 - val_accuracy: 0.1800\n",
            "Epoch 25/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.4014 - accuracy: 0.1640\n",
            "Epoch 00025: val_loss improved from 3.36882 to 3.31477, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.4014 - accuracy: 0.1640 - val_loss: 3.3148 - val_accuracy: 0.1890\n",
            "Epoch 26/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.3523 - accuracy: 0.1712\n",
            "Epoch 00026: val_loss improved from 3.31477 to 3.28202, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.3523 - accuracy: 0.1712 - val_loss: 3.2820 - val_accuracy: 0.1944\n",
            "Epoch 27/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.3066 - accuracy: 0.1794\n",
            "Epoch 00027: val_loss improved from 3.28202 to 3.28184, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 3.3066 - accuracy: 0.1794 - val_loss: 3.2818 - val_accuracy: 0.1954\n",
            "Epoch 28/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.2660 - accuracy: 0.1855\n",
            "Epoch 00028: val_loss improved from 3.28184 to 3.19373, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 3.2660 - accuracy: 0.1855 - val_loss: 3.1937 - val_accuracy: 0.2101\n",
            "Epoch 29/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.2215 - accuracy: 0.1911\n",
            "Epoch 00029: val_loss improved from 3.19373 to 3.16138, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 154ms/step - loss: 3.2215 - accuracy: 0.1911 - val_loss: 3.1614 - val_accuracy: 0.2177\n",
            "Epoch 30/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.1731 - accuracy: 0.2043\n",
            "Epoch 00030: val_loss improved from 3.16138 to 3.15035, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 154ms/step - loss: 3.1731 - accuracy: 0.2043 - val_loss: 3.1503 - val_accuracy: 0.2206\n",
            "Epoch 31/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.1332 - accuracy: 0.2116\n",
            "Epoch 00031: val_loss improved from 3.15035 to 3.09040, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 3.1332 - accuracy: 0.2116 - val_loss: 3.0904 - val_accuracy: 0.2330\n",
            "Epoch 32/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.0924 - accuracy: 0.2196\n",
            "Epoch 00032: val_loss improved from 3.09040 to 3.06742, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 154ms/step - loss: 3.0924 - accuracy: 0.2196 - val_loss: 3.0674 - val_accuracy: 0.2390\n",
            "Epoch 33/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.0539 - accuracy: 0.2248\n",
            "Epoch 00033: val_loss improved from 3.06742 to 3.02762, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 3.0539 - accuracy: 0.2248 - val_loss: 3.0276 - val_accuracy: 0.2454\n",
            "Epoch 34/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.0105 - accuracy: 0.2363\n",
            "Epoch 00034: val_loss did not improve from 3.02762\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 3.0105 - accuracy: 0.2363 - val_loss: 3.0303 - val_accuracy: 0.2473\n",
            "Epoch 35/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.9681 - accuracy: 0.2449\n",
            "Epoch 00035: val_loss improved from 3.02762 to 2.96112, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.9681 - accuracy: 0.2449 - val_loss: 2.9611 - val_accuracy: 0.2567\n",
            "Epoch 36/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.9275 - accuracy: 0.2503\n",
            "Epoch 00036: val_loss improved from 2.96112 to 2.92321, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.9275 - accuracy: 0.2503 - val_loss: 2.9232 - val_accuracy: 0.2639\n",
            "Epoch 37/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8939 - accuracy: 0.2569\n",
            "Epoch 00037: val_loss improved from 2.92321 to 2.91753, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.8939 - accuracy: 0.2569 - val_loss: 2.9175 - val_accuracy: 0.2693\n",
            "Epoch 38/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8558 - accuracy: 0.2619\n",
            "Epoch 00038: val_loss improved from 2.91753 to 2.89276, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.8558 - accuracy: 0.2619 - val_loss: 2.8928 - val_accuracy: 0.2719\n",
            "Epoch 39/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8143 - accuracy: 0.2714\n",
            "Epoch 00039: val_loss improved from 2.89276 to 2.87745, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.8143 - accuracy: 0.2714 - val_loss: 2.8774 - val_accuracy: 0.2703\n",
            "Epoch 40/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.7827 - accuracy: 0.2783\n",
            "Epoch 00040: val_loss improved from 2.87745 to 2.83220, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.7827 - accuracy: 0.2783 - val_loss: 2.8322 - val_accuracy: 0.2778\n",
            "Epoch 41/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.7450 - accuracy: 0.2851\n",
            "Epoch 00041: val_loss improved from 2.83220 to 2.79773, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.7450 - accuracy: 0.2851 - val_loss: 2.7977 - val_accuracy: 0.2896\n",
            "Epoch 42/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.7141 - accuracy: 0.2915\n",
            "Epoch 00042: val_loss did not improve from 2.79773\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.7141 - accuracy: 0.2915 - val_loss: 2.8035 - val_accuracy: 0.2897\n",
            "Epoch 43/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.6812 - accuracy: 0.2975\n",
            "Epoch 00043: val_loss improved from 2.79773 to 2.76764, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.6812 - accuracy: 0.2975 - val_loss: 2.7676 - val_accuracy: 0.2943\n",
            "Epoch 44/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.6447 - accuracy: 0.3052\n",
            "Epoch 00044: val_loss improved from 2.76764 to 2.76586, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.6447 - accuracy: 0.3052 - val_loss: 2.7659 - val_accuracy: 0.2909\n",
            "Epoch 45/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.6125 - accuracy: 0.3128\n",
            "Epoch 00045: val_loss did not improve from 2.76586\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.6125 - accuracy: 0.3128 - val_loss: 2.7897 - val_accuracy: 0.2924\n",
            "Epoch 46/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.5795 - accuracy: 0.3178\n",
            "Epoch 00046: val_loss improved from 2.76586 to 2.76003, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.5795 - accuracy: 0.3178 - val_loss: 2.7600 - val_accuracy: 0.3013\n",
            "Epoch 47/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.5463 - accuracy: 0.3248\n",
            "Epoch 00047: val_loss did not improve from 2.76003\n",
            "196/196 [==============================] - 30s 151ms/step - loss: 2.5463 - accuracy: 0.3248 - val_loss: 2.7883 - val_accuracy: 0.2917\n",
            "Epoch 48/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.5168 - accuracy: 0.3294\n",
            "Epoch 00048: val_loss improved from 2.76003 to 2.74170, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.5168 - accuracy: 0.3294 - val_loss: 2.7417 - val_accuracy: 0.3021\n",
            "Epoch 49/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4795 - accuracy: 0.3380\n",
            "Epoch 00049: val_loss improved from 2.74170 to 2.68539, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.4795 - accuracy: 0.3380 - val_loss: 2.6854 - val_accuracy: 0.3175\n",
            "Epoch 50/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4482 - accuracy: 0.3450\n",
            "Epoch 00050: val_loss did not improve from 2.68539\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.4482 - accuracy: 0.3450 - val_loss: 2.7134 - val_accuracy: 0.3083\n",
            "Epoch 51/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4123 - accuracy: 0.3496\n",
            "Epoch 00051: val_loss did not improve from 2.68539\n",
            "196/196 [==============================] - 30s 151ms/step - loss: 2.4123 - accuracy: 0.3496 - val_loss: 2.6870 - val_accuracy: 0.3177\n",
            "Epoch 52/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.3817 - accuracy: 0.3574\n",
            "Epoch 00052: val_loss did not improve from 2.68539\n",
            "196/196 [==============================] - 30s 151ms/step - loss: 2.3817 - accuracy: 0.3574 - val_loss: 2.7617 - val_accuracy: 0.3089\n",
            "Epoch 53/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.3487 - accuracy: 0.3667\n",
            "Epoch 00053: val_loss improved from 2.68539 to 2.66494, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.3487 - accuracy: 0.3667 - val_loss: 2.6649 - val_accuracy: 0.3238\n",
            "Epoch 54/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.3137 - accuracy: 0.3730\n",
            "Epoch 00054: val_loss did not improve from 2.66494\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.3137 - accuracy: 0.3730 - val_loss: 2.6667 - val_accuracy: 0.3192\n",
            "Epoch 55/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.2843 - accuracy: 0.3797\n",
            "Epoch 00055: val_loss improved from 2.66494 to 2.65401, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.2843 - accuracy: 0.3797 - val_loss: 2.6540 - val_accuracy: 0.3244\n",
            "Epoch 56/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.2495 - accuracy: 0.3861\n",
            "Epoch 00056: val_loss improved from 2.65401 to 2.63034, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.2495 - accuracy: 0.3861 - val_loss: 2.6303 - val_accuracy: 0.3294\n",
            "Epoch 57/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.2149 - accuracy: 0.3966\n",
            "Epoch 00057: val_loss did not improve from 2.63034\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.2149 - accuracy: 0.3966 - val_loss: 2.6322 - val_accuracy: 0.3355\n",
            "Epoch 58/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.1820 - accuracy: 0.3987\n",
            "Epoch 00058: val_loss improved from 2.63034 to 2.61585, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.1820 - accuracy: 0.3987 - val_loss: 2.6158 - val_accuracy: 0.3390\n",
            "Epoch 59/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.1482 - accuracy: 0.4085\n",
            "Epoch 00059: val_loss did not improve from 2.61585\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.1482 - accuracy: 0.4085 - val_loss: 2.6712 - val_accuracy: 0.3328\n",
            "Epoch 60/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.1209 - accuracy: 0.4125\n",
            "Epoch 00060: val_loss improved from 2.61585 to 2.60728, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 2.1209 - accuracy: 0.4125 - val_loss: 2.6073 - val_accuracy: 0.3393\n",
            "Epoch 61/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.0774 - accuracy: 0.4235\n",
            "Epoch 00061: val_loss did not improve from 2.60728\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.0774 - accuracy: 0.4235 - val_loss: 2.6825 - val_accuracy: 0.3379\n",
            "Epoch 62/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.0470 - accuracy: 0.4301\n",
            "Epoch 00062: val_loss did not improve from 2.60728\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.0470 - accuracy: 0.4301 - val_loss: 2.6909 - val_accuracy: 0.3302\n",
            "Epoch 63/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.0088 - accuracy: 0.4373\n",
            "Epoch 00063: val_loss did not improve from 2.60728\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 2.0088 - accuracy: 0.4373 - val_loss: 2.6633 - val_accuracy: 0.3371\n",
            "Epoch 64/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.9768 - accuracy: 0.4450\n",
            "Epoch 00064: val_loss improved from 2.60728 to 2.60592, saving model to InceptionV2_SGD_Dropout.h5\n",
            "196/196 [==============================] - 30s 153ms/step - loss: 1.9768 - accuracy: 0.4450 - val_loss: 2.6059 - val_accuracy: 0.3450\n",
            "Epoch 65/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.9459 - accuracy: 0.4536\n",
            "Epoch 00065: val_loss did not improve from 2.60592\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 1.9459 - accuracy: 0.4536 - val_loss: 2.6860 - val_accuracy: 0.3357\n",
            "Epoch 66/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.9119 - accuracy: 0.4602\n",
            "Epoch 00066: val_loss did not improve from 2.60592\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 1.9119 - accuracy: 0.4602 - val_loss: 2.6259 - val_accuracy: 0.3480\n",
            "Epoch 67/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8746 - accuracy: 0.4689\n",
            "Epoch 00067: val_loss did not improve from 2.60592\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 1.8746 - accuracy: 0.4689 - val_loss: 2.7002 - val_accuracy: 0.3428\n",
            "Epoch 68/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8398 - accuracy: 0.4750\n",
            "Epoch 00068: val_loss did not improve from 2.60592\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 1.8398 - accuracy: 0.4750 - val_loss: 2.7044 - val_accuracy: 0.3388\n",
            "Epoch 69/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 1.8063 - accuracy: 0.4829\n",
            "Epoch 00069: val_loss did not improve from 2.60592\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 1.8063 - accuracy: 0.4829 - val_loss: 2.6953 - val_accuracy: 0.3415\n",
            "Epoch 00069: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0xFUMyq_tGF"
      },
      "source": [
        "<h3><b> Graphs</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4tGzn_O_n14",
        "outputId": "fa1d1a2d-6e35-4a09-c4b9-29863177b31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "accuracy_values = history_dict['accuracy']\n",
        "val_accuracy_values = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, accuracy_values, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDpykeG_pdP",
        "outputId": "a253dbdb-320a-45c3-f5de-1a99e3ca9fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2CBsx5a2h8O"
      },
      "source": [
        "<h3><b> Metric Calculation</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOhTm_r5_68l",
        "outputId": "2c8b2c49-1968-4b54-f74c-9f74ab713435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model1 = Model(input_layer,  output)\n",
        "model1.load_weights(\"./InceptionV2_SGD_Dropout.h5\")\n",
        "#optimization details\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "lr_decay = 1e-6\n",
        "#optimization details\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "# Test the model\n",
        "model.predict(X_test).argmax(-1)\n",
        "\n",
        "y_true = y_test.argmax(-1)\n",
        "y_pred = model.predict(X_test).argmax(-1)\n",
        "# generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "confusion_matrix(y_true, y_pred)\n",
        "# calculate prec, recall, accuracy\n",
        "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prec: 0.34073495309576257\n",
            "Recall: 0.345\n",
            "Accuracy: 0.345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_M6ri2847o1"
      },
      "source": [
        "<h3><b> References</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2G22fKjJEF"
      },
      "source": [
        "#https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/\n",
        "#https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}