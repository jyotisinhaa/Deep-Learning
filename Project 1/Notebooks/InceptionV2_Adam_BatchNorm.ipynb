{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyOazSpWztcP"
   },
   "source": [
    "<h3><b> Importing Library</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "XNYk17cCS0lA"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import math \n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3XLVJepz2DV"
   },
   "source": [
    "<h3><b> Importing Dataset</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "iuhv097NYrfu",
    "outputId": "2d4dee26-7ed8-4846-e259-9122d740bca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2yAtEqs0DTO"
   },
   "source": [
    "<h3><b> Preprocessing of the dataset</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "G1xMv3g8Yxl4"
   },
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "NUcSJ9bPY4Yu"
   },
   "outputs": [],
   "source": [
    "#Converting the testing and training dataset into float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0UfXOG68Y741",
    "outputId": "c8cfb35c-5c9d-4e2c-ea53-18e8166809a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Convert training and test labels to one hot matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtqhVwFs0_yO"
   },
   "source": [
    "<h3><b> Model Architecure</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "RLLcjHtgid1I"
   },
   "outputs": [],
   "source": [
    "def inception_moduleA(x,\n",
    "                     filters_1x1,\n",
    "                     filters_3x3_reduce,\n",
    "                     filters_3x3,\n",
    "                     filters_5x5_reduce,\n",
    "                     filters_3x3a,\n",
    "                      filters_3x3b,\n",
    "                  \n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='elu')(x)\n",
    "    \n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='elu')(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_3x3a = Conv2D(filters_3x3a, (3, 3), padding='same', activation='elu')(conv_5x5)\n",
    "    conv_3x3b = Conv2D(filters_3x3b, (3, 3), padding='same', activation='elu')(conv_3x3a)\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_3x3a, pool_proj], axis=-1, name=name)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def inception_moduleB(x,\n",
    "                     filters_1x1modb,\n",
    "                     filters_3x3_reducemodb,\n",
    "                     filters_1x3modb,\n",
    "                     filters_3x1modb,\n",
    "                     filters_5x5_reducemodb,\n",
    "                     filters_1x3amodb,\n",
    "                      filters_3x1amodb,\n",
    "                     filters_1x3bmodb,\n",
    "                      filters_3x1bmodb,\n",
    "                  \n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1modb = Conv2D(filters_1x1modb, (1, 1), padding='same', activation='elu')(x)\n",
    "    \n",
    "    conv_3x3modb = Conv2D(filters_3x3_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_1x3modb = Conv2D(filters_1x3modb, (1, 3), padding='same', activation='elu')(conv_3x3modb)\n",
    "    conv_3x1modb = Conv2D(filters_3x1modb, (3, 1), padding='same', activation='elu')(conv_1x3modb)\n",
    "\n",
    "    conv_5x5modb = Conv2D(filters_5x5_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_1x3amodb = Conv2D(filters_1x3amodb, (1, 3), padding='same', activation='elu')(conv_5x5modb)\n",
    "    conv_3x1amodb = Conv2D(filters_3x1amodb, (3, 1), padding='same', activation='elu')(conv_1x3amodb)\n",
    "    conv_1x3bmodb = Conv2D(filters_1x3bmodb, (1, 3), padding='same', activation='elu')(conv_3x1amodb)\n",
    "    conv_3x1bmodb = Conv2D(filters_3x1bmodb, (3, 1), padding='same', activation='elu')(conv_1x3bmodb)\n",
    "\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1modb, conv_3x1modb, conv_3x1bmodb, pool_proj], axis=-1, name=name)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def inception_moduleC(x,\n",
    "                     filters_1x1modc,\n",
    "                      filters_3x3_reducemodc,\n",
    "                     filters_1x3modc,\n",
    "                      filters_3x1modc,\n",
    "                     filters_5x5_reducemodc,\n",
    "                        filters_3x3amodc,\n",
    "                      filters_1x3amodc,\n",
    "                       filters_3x1amodc,\n",
    "                      \n",
    "                   \n",
    "                     filters_pool_proj,\n",
    "                     name=None):\n",
    "    \n",
    "    conv_1x1modc = Conv2D(filters_1x1modc, (1, 1), padding='same', activation='elu')(x)\n",
    "    \n",
    "    conv_3x3modc = Conv2D(filters_3x3_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_1x3modc = Conv2D(filters_1x3modc, (1, 3), padding='same', activation='elu')(conv_3x3modc)\n",
    "    conv_3x1modc = Conv2D(filters_3x1modc, (3, 1), padding='same', activation='elu')(conv_1x3modc)\n",
    "\n",
    "    conv_5x5modc = Conv2D(filters_5x5_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
    "    conv_3x3amodc = Conv2D(filters_3x3amodc, (1, 1), padding='same', activation='elu')(conv_5x5modc)\n",
    "\n",
    "    conv_1x3amodc = Conv2D(filters_1x3amodc, (1, 3), padding='same', activation='elu')(conv_3x3amodc)\n",
    "    conv_3x1amodc = Conv2D(filters_3x1amodc, (3, 1), padding='same', activation='elu')(conv_1x3amodc)\n",
    "\n",
    "\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1modc,conv_1x3modc, conv_3x1modc, conv_1x3amodc,conv_3x1amodc, pool_proj], axis=-1, name=name)\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "br3rOWOzHxJJ"
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_1a_3x3/2')(input_layer)\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_2a_3x3/1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_3a_3x3/1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_4a_3x3/1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_5a_3x3/2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_6a_3x3/1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = inception_moduleA(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_3x3a=32,\n",
    "                     filters_3x3b=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "x = inception_moduleA(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_3x3a=32,\n",
    "                     filters_3x3b=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3aa')\n",
    "\n",
    "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
    "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
    "# x = inception_moduleA(x,\n",
    "#                      filters_1x1=64,\n",
    "#                      filters_3x3_reduce=96,\n",
    "#                      filters_3x3=128,\n",
    "#                      filters_5x5_reduce=16,\n",
    "#                      filters_3x3a=32,\n",
    "#                      filters_3x3b=32,\n",
    "#                      filters_pool_proj=32,\n",
    "#                      name='inception_3aaa')\n",
    "\n",
    "x = inception_moduleB(x,\n",
    "                     filters_1x1modb=64,\n",
    "                     filters_3x3_reducemodb=96,\n",
    "                     filters_1x3modb=128,\n",
    "                     filters_3x1modb=128,\n",
    "                     filters_5x5_reducemodb=16,\n",
    "                     filters_1x3amodb=128,\n",
    "                     filters_3x1amodb=128,\n",
    "                     filters_1x3bmodb=128,\n",
    "                     filters_3x1bmodb=128,\n",
    "                   filters_pool_proj=32,\n",
    "                     name='inception_4a')\n",
    "x = inception_moduleB(x,\n",
    "                     filters_1x1modb=64,\n",
    "                     filters_3x3_reducemodb=96,\n",
    "                     filters_1x3modb=128,\n",
    "                     filters_3x1modb=128,\n",
    "                     filters_5x5_reducemodb=16,\n",
    "                     filters_1x3amodb=128,\n",
    "                     filters_3x1amodb=128,\n",
    "                     filters_1x3bmodb=128,\n",
    "                     filters_3x1bmodb=128,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_4aa')\n",
    "x = inception_moduleB(x,\n",
    "                     filters_1x1modb=64,\n",
    "                     filters_3x3_reducemodb=96,\n",
    "                     filters_1x3modb=128,\n",
    "                     filters_3x1modb=128,\n",
    "                     filters_5x5_reducemodb=16,\n",
    "                     filters_1x3amodb=128,\n",
    "                     filters_3x1amodb=128,\n",
    "                     filters_1x3bmodb=128,\n",
    "                     filters_3x1bmodb=128,\n",
    "                      filters_pool_proj=32,\n",
    "             \n",
    "                     name='inception_4aaa')\n",
    "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
    "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
    "# x = inception_moduleB(x,\n",
    "#                      filters_1x1modb=64,\n",
    "#                      filters_3x3_reducemodb=96,\n",
    "#                      filters_1x3modb=128,\n",
    "#                      filters_3x1modb=128,\n",
    "#                      filters_5x5_reducemodb=16,\n",
    "#                      filters_1x3amodb=128,\n",
    "#                      filters_3x1amodb=128,\n",
    "#                      filters_1x3bmodb=128,\n",
    "#                      filters_3x1bmodb=128,\n",
    "#                      filters_pool_proj=32,\n",
    "#                      name='inception_4aaaa')\n",
    "# x = inception_moduleB(x,\n",
    "#                      filters_1x1modb=64,\n",
    "#                      filters_3x3_reducemodb=96,\n",
    "#                      filters_1x3modb=128,\n",
    "#                      filters_3x1modb=128,\n",
    "#                      filters_5x5_reducemodb=16,\n",
    "#                      filters_1x3amodb=128,\n",
    "#                      filters_3x1amodb=128,\n",
    "#                      filters_1x3bmodb=128,\n",
    "#                      filters_3x1bmodb=128,\n",
    "#                      filters_pool_proj=32,\n",
    "#                      name='inception_4aaaaa')\n",
    "\n",
    "x = inception_moduleC(x,\n",
    "                     filters_1x1modc=64,\n",
    "                     filters_3x3_reducemodc=96,\n",
    "                     filters_1x3modc=128,\n",
    "                     filters_3x1modc=128,\n",
    "                     filters_5x5_reducemodc=16,\n",
    "                     filters_3x3amodc=128,\n",
    "                     filters_1x3amodc=128,\n",
    "                     filters_3x1amodc=128,\n",
    "                     filters_pool_proj=32,\n",
    "                    \n",
    "                     name='inception_5a')\n",
    "x = inception_moduleC(x,\n",
    "                     filters_1x1modc=64,\n",
    "                     filters_3x3_reducemodc=96,\n",
    "                     filters_1x3modc=128,\n",
    "                     filters_3x1modc=128,\n",
    "                     filters_5x5_reducemodc=16,\n",
    "                     filters_3x3amodc=128,\n",
    "                     filters_1x3amodc=128,\n",
    "                     filters_3x1amodc=128,\n",
    "                     filters_pool_proj=32,\n",
    "             \n",
    "                     name='inception_5aa')\n",
    "\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "x = Flatten()(x)\n",
    "output = Dense(100, activation='softmax', name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "7GWOmOi_qTCS"
   },
   "outputs": [],
   "source": [
    "model = Model(input_layer,  output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ok_nFUWbFuwg",
    "outputId": "719d5fc5-9f58-4257-efc8-d387f2cb41b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1a_3x3/2 (Conv2D)          (None, 16, 16, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_2a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       conv_1a_3x3/2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv_2a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv_3a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_2_3x3/2 (MaxPooling2D) (None, 8, 8, 64)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4a_3x3/1 (Conv2D)          (None, 8, 8, 64)     36928       max_pool_2_3x3/2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv_4a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_5a_3x3/2 (Conv2D)          (None, 4, 4, 64)     36928       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 64)     256         conv_5a_3x3/2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_6a_3x3/1 (Conv2D)          (None, 4, 4, 64)     36928       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 64)     256         conv_6a_3x3/1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 4, 4, 96)     6240        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 4, 4, 16)     1040        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 4, 4, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 4, 4, 64)     4160        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 4, 4, 128)    110720      conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 4, 4, 32)     4640        conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 4, 4, 32)     2080        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a (Concatenate)      (None, 4, 4, 256)    0           conv2d_186[0][0]                 \n",
      "                                                                 conv2d_188[0][0]                 \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "                                                                 conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 4, 4, 96)     24672       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 4, 4, 16)     4112        inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 4, 4, 256)    0           inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 4, 4, 64)     16448       inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 4, 4, 128)    110720      conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 4, 4, 32)     4640        conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 4, 4, 32)     8224        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3aa (Concatenate)     (None, 4, 4, 256)    0           conv2d_193[0][0]                 \n",
      "                                                                 conv2d_195[0][0]                 \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 4, 4, 16)     4112        inception_3aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 4, 4, 128)    6272        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 4, 4, 96)     24672       inception_3aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 4, 4, 128)    36992       conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 4, 4, 256)    0           inception_3aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 4, 4, 64)     16448       inception_3aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 4, 4, 32)     8224        max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a (Concatenate)      (None, 4, 4, 352)    0           conv2d_200[0][0]                 \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "                                                                 conv2d_208[0][0]                 \n",
      "                                                                 conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 4, 4, 16)     5648        inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 4, 4, 128)    6272        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 4, 4, 96)     33888       inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 4, 4, 128)    36992       conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 4, 4, 352)    0           inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 4, 4, 64)     22592       inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 4, 4, 32)     11296       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4aa (Concatenate)     (None, 4, 4, 352)    0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "                                                                 conv2d_218[0][0]                 \n",
      "                                                                 conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 4, 4, 16)     5648        inception_4aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 4, 4, 128)    6272        conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 4, 4, 96)     33888       inception_4aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 4, 4, 128)    36992       conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 4, 4, 352)    0           inception_4aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 4, 4, 64)     22592       inception_4aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 4, 4, 32)     11296       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4aaa (Concatenate)    (None, 4, 4, 352)    0           conv2d_220[0][0]                 \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "                                                                 conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 4, 4, 16)     5648        inception_4aaa[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 4, 4, 96)     33888       inception_4aaa[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 4, 4, 128)    2176        conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 4, 4, 128)    36992       conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 4, 4, 352)    0           inception_4aaa[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 4, 4, 64)     22592       inception_4aaa[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 4, 4, 32)     11296       max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a (Concatenate)      (None, 4, 4, 608)    0           conv2d_230[0][0]                 \n",
      "                                                                 conv2d_232[0][0]                 \n",
      "                                                                 conv2d_233[0][0]                 \n",
      "                                                                 conv2d_236[0][0]                 \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 4, 4, 16)     9744        inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 4, 4, 96)     58464       inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 4, 4, 128)    2176        conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 4, 4, 128)    36992       conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 4, 4, 608)    0           inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 4, 4, 64)     38976       inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 4, 4, 128)    49280       conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 4, 4, 32)     19488       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_5aa (Concatenate)     (None, 4, 4, 608)    0           conv2d_239[0][0]                 \n",
      "                                                                 conv2d_241[0][0]                 \n",
      "                                                                 conv2d_242[0][0]                 \n",
      "                                                                 conv2d_245[0][0]                 \n",
      "                                                                 conv2d_246[0][0]                 \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_5_3x3/1 (GlobalAverage (None, 608)          0           inception_5aa[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 608)          0           avg_pool_5_3x3/1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 100)          60900       flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,041,876\n",
      "Trainable params: 2,041,236\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-jkzpVu1SSF"
   },
   "source": [
    "<h3><b> Model Compile</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YPd9gc_sBziE"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "batch_size = 128\n",
    "lr_decay = 1e-6\n",
    "#optimization details\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "u_rq-y4K1rgo",
    "outputId": "8cf49317-399e-45b9-83e6-2d97365161c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create Checkpoint and Early Stopping\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"InceptionV2_Adam_BatchNorm.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HogWDFCh1ZxX"
   },
   "source": [
    "<h3><b> Train the Model</b><h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cxkeVrtvF0Ok",
    "outputId": "c6ae04e4-4161-48bb-b0d6-761ab01ffa1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  2/196 [..............................] - ETA: 17s - loss: 4.6157 - accuracy: 0.0215WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0589s vs `on_train_batch_end` time: 0.1226s). Check your callbacks.\n",
      "196/196 [==============================] - ETA: 0s - loss: 4.5051 - accuracy: 0.0328\n",
      "Epoch 00001: val_loss improved from inf to 4.61528, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 156ms/step - loss: 4.5051 - accuracy: 0.0328 - val_loss: 4.6153 - val_accuracy: 0.0132\n",
      "Epoch 2/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 4.1865 - accuracy: 0.0642\n",
      "Epoch 00002: val_loss improved from 4.61528 to 4.43509, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 4.1865 - accuracy: 0.0642 - val_loss: 4.4351 - val_accuracy: 0.0346\n",
      "Epoch 3/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.9395 - accuracy: 0.0941\n",
      "Epoch 00003: val_loss improved from 4.43509 to 3.96363, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 3.9395 - accuracy: 0.0941 - val_loss: 3.9636 - val_accuracy: 0.0887\n",
      "Epoch 4/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.7887 - accuracy: 0.1139\n",
      "Epoch 00004: val_loss improved from 3.96363 to 3.78345, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 3.7887 - accuracy: 0.1139 - val_loss: 3.7835 - val_accuracy: 0.1112\n",
      "Epoch 5/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.6858 - accuracy: 0.1282\n",
      "Epoch 00005: val_loss improved from 3.78345 to 3.65608, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 3.6858 - accuracy: 0.1282 - val_loss: 3.6561 - val_accuracy: 0.1318\n",
      "Epoch 6/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.5982 - accuracy: 0.1409\n",
      "Epoch 00006: val_loss improved from 3.65608 to 3.58730, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 3.5982 - accuracy: 0.1409 - val_loss: 3.5873 - val_accuracy: 0.1430\n",
      "Epoch 7/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.5189 - accuracy: 0.1519\n",
      "Epoch 00007: val_loss improved from 3.58730 to 3.52580, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.5189 - accuracy: 0.1519 - val_loss: 3.5258 - val_accuracy: 0.1499\n",
      "Epoch 8/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.4461 - accuracy: 0.1640\n",
      "Epoch 00008: val_loss improved from 3.52580 to 3.46822, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.4461 - accuracy: 0.1640 - val_loss: 3.4682 - val_accuracy: 0.1627\n",
      "Epoch 9/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.3844 - accuracy: 0.1759\n",
      "Epoch 00009: val_loss improved from 3.46822 to 3.40882, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.3844 - accuracy: 0.1759 - val_loss: 3.4088 - val_accuracy: 0.1711\n",
      "Epoch 10/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.3257 - accuracy: 0.1849\n",
      "Epoch 00010: val_loss improved from 3.40882 to 3.35350, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.3257 - accuracy: 0.1849 - val_loss: 3.3535 - val_accuracy: 0.1822\n",
      "Epoch 11/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.2751 - accuracy: 0.1935\n",
      "Epoch 00011: val_loss improved from 3.35350 to 3.31732, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.2751 - accuracy: 0.1935 - val_loss: 3.3173 - val_accuracy: 0.1910\n",
      "Epoch 12/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.2263 - accuracy: 0.2028\n",
      "Epoch 00012: val_loss improved from 3.31732 to 3.27089, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 3.2263 - accuracy: 0.2028 - val_loss: 3.2709 - val_accuracy: 0.1953\n",
      "Epoch 13/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.1793 - accuracy: 0.2123\n",
      "Epoch 00013: val_loss improved from 3.27089 to 3.25630, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 3.1793 - accuracy: 0.2123 - val_loss: 3.2563 - val_accuracy: 0.2009\n",
      "Epoch 14/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.1361 - accuracy: 0.2202\n",
      "Epoch 00014: val_loss improved from 3.25630 to 3.19931, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 3.1361 - accuracy: 0.2202 - val_loss: 3.1993 - val_accuracy: 0.2128\n",
      "Epoch 15/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.0966 - accuracy: 0.2272\n",
      "Epoch 00015: val_loss improved from 3.19931 to 3.17600, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 3.0966 - accuracy: 0.2272 - val_loss: 3.1760 - val_accuracy: 0.2168\n",
      "Epoch 16/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.0590 - accuracy: 0.2357\n",
      "Epoch 00016: val_loss improved from 3.17600 to 3.16750, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.0590 - accuracy: 0.2357 - val_loss: 3.1675 - val_accuracy: 0.2193\n",
      "Epoch 17/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 3.0228 - accuracy: 0.2414\n",
      "Epoch 00017: val_loss improved from 3.16750 to 3.10729, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 3.0228 - accuracy: 0.2414 - val_loss: 3.1073 - val_accuracy: 0.2285\n",
      "Epoch 18/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.9873 - accuracy: 0.2493\n",
      "Epoch 00018: val_loss improved from 3.10729 to 3.08250, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.9873 - accuracy: 0.2493 - val_loss: 3.0825 - val_accuracy: 0.2315\n",
      "Epoch 19/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.9551 - accuracy: 0.2524\n",
      "Epoch 00019: val_loss improved from 3.08250 to 3.06553, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.9551 - accuracy: 0.2524 - val_loss: 3.0655 - val_accuracy: 0.2348\n",
      "Epoch 20/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.9260 - accuracy: 0.2595\n",
      "Epoch 00020: val_loss improved from 3.06553 to 3.04837, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.9260 - accuracy: 0.2595 - val_loss: 3.0484 - val_accuracy: 0.2400\n",
      "Epoch 21/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.8949 - accuracy: 0.2648\n",
      "Epoch 00021: val_loss improved from 3.04837 to 3.02343, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.8949 - accuracy: 0.2648 - val_loss: 3.0234 - val_accuracy: 0.2468\n",
      "Epoch 22/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.8665 - accuracy: 0.2716\n",
      "Epoch 00022: val_loss improved from 3.02343 to 3.01291, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.8665 - accuracy: 0.2716 - val_loss: 3.0129 - val_accuracy: 0.2485\n",
      "Epoch 23/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.8404 - accuracy: 0.2769\n",
      "Epoch 00023: val_loss improved from 3.01291 to 2.99893, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.8404 - accuracy: 0.2769 - val_loss: 2.9989 - val_accuracy: 0.2475\n",
      "Epoch 24/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.8142 - accuracy: 0.2816\n",
      "Epoch 00024: val_loss improved from 2.99893 to 2.96183, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.8142 - accuracy: 0.2816 - val_loss: 2.9618 - val_accuracy: 0.2591\n",
      "Epoch 25/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.7887 - accuracy: 0.2868\n",
      "Epoch 00025: val_loss improved from 2.96183 to 2.95190, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.7887 - accuracy: 0.2868 - val_loss: 2.9519 - val_accuracy: 0.2606\n",
      "Epoch 26/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.7686 - accuracy: 0.2907\n",
      "Epoch 00026: val_loss improved from 2.95190 to 2.92985, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.7686 - accuracy: 0.2907 - val_loss: 2.9299 - val_accuracy: 0.2637\n",
      "Epoch 27/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.7443 - accuracy: 0.2956\n",
      "Epoch 00027: val_loss improved from 2.92985 to 2.90914, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 2.7443 - accuracy: 0.2956 - val_loss: 2.9091 - val_accuracy: 0.2665\n",
      "Epoch 28/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.7229 - accuracy: 0.3003\n",
      "Epoch 00028: val_loss improved from 2.90914 to 2.89193, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.7229 - accuracy: 0.3003 - val_loss: 2.8919 - val_accuracy: 0.2724\n",
      "Epoch 29/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.7022 - accuracy: 0.3034\n",
      "Epoch 00029: val_loss did not improve from 2.89193\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.7022 - accuracy: 0.3034 - val_loss: 2.8950 - val_accuracy: 0.2711\n",
      "Epoch 30/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.6820 - accuracy: 0.3098\n",
      "Epoch 00030: val_loss did not improve from 2.89193\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.6820 - accuracy: 0.3098 - val_loss: 2.9176 - val_accuracy: 0.2701\n",
      "Epoch 31/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.6600 - accuracy: 0.3118\n",
      "Epoch 00031: val_loss improved from 2.89193 to 2.86760, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.6600 - accuracy: 0.3118 - val_loss: 2.8676 - val_accuracy: 0.2783\n",
      "Epoch 32/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.6423 - accuracy: 0.3160\n",
      "Epoch 00032: val_loss improved from 2.86760 to 2.84733, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.6423 - accuracy: 0.3160 - val_loss: 2.8473 - val_accuracy: 0.2822\n",
      "Epoch 33/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.6223 - accuracy: 0.3203\n",
      "Epoch 00033: val_loss improved from 2.84733 to 2.83626, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.6223 - accuracy: 0.3203 - val_loss: 2.8363 - val_accuracy: 0.2835\n",
      "Epoch 34/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.6068 - accuracy: 0.3237\n",
      "Epoch 00034: val_loss improved from 2.83626 to 2.83256, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.6068 - accuracy: 0.3237 - val_loss: 2.8326 - val_accuracy: 0.2869\n",
      "Epoch 35/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5881 - accuracy: 0.3275\n",
      "Epoch 00035: val_loss did not improve from 2.83256\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.5881 - accuracy: 0.3275 - val_loss: 2.8646 - val_accuracy: 0.2828\n",
      "Epoch 36/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5690 - accuracy: 0.3317\n",
      "Epoch 00036: val_loss improved from 2.83256 to 2.82071, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.5690 - accuracy: 0.3317 - val_loss: 2.8207 - val_accuracy: 0.2847\n",
      "Epoch 37/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5518 - accuracy: 0.3340\n",
      "Epoch 00037: val_loss improved from 2.82071 to 2.81448, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.5518 - accuracy: 0.3340 - val_loss: 2.8145 - val_accuracy: 0.2878\n",
      "Epoch 38/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5374 - accuracy: 0.3373\n",
      "Epoch 00038: val_loss improved from 2.81448 to 2.79220, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.5374 - accuracy: 0.3373 - val_loss: 2.7922 - val_accuracy: 0.2896\n",
      "Epoch 39/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5198 - accuracy: 0.3410\n",
      "Epoch 00039: val_loss improved from 2.79220 to 2.78914, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.5198 - accuracy: 0.3410 - val_loss: 2.7891 - val_accuracy: 0.2947\n",
      "Epoch 40/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.5056 - accuracy: 0.3448\n",
      "Epoch 00040: val_loss did not improve from 2.78914\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.5056 - accuracy: 0.3448 - val_loss: 2.8166 - val_accuracy: 0.2877\n",
      "Epoch 41/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4871 - accuracy: 0.3471\n",
      "Epoch 00041: val_loss improved from 2.78914 to 2.77993, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.4871 - accuracy: 0.3471 - val_loss: 2.7799 - val_accuracy: 0.3008\n",
      "Epoch 42/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4742 - accuracy: 0.3505\n",
      "Epoch 00042: val_loss did not improve from 2.77993\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.4742 - accuracy: 0.3505 - val_loss: 2.8215 - val_accuracy: 0.2927\n",
      "Epoch 43/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4602 - accuracy: 0.3535\n",
      "Epoch 00043: val_loss did not improve from 2.77993\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.4602 - accuracy: 0.3535 - val_loss: 2.7805 - val_accuracy: 0.2960\n",
      "Epoch 44/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4446 - accuracy: 0.3568\n",
      "Epoch 00044: val_loss improved from 2.77993 to 2.75503, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.4446 - accuracy: 0.3568 - val_loss: 2.7550 - val_accuracy: 0.3017\n",
      "Epoch 45/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4307 - accuracy: 0.3602\n",
      "Epoch 00045: val_loss did not improve from 2.75503\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.4307 - accuracy: 0.3602 - val_loss: 2.8074 - val_accuracy: 0.2969\n",
      "Epoch 46/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4154 - accuracy: 0.3628\n",
      "Epoch 00046: val_loss did not improve from 2.75503\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.4154 - accuracy: 0.3628 - val_loss: 2.7600 - val_accuracy: 0.2997\n",
      "Epoch 47/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.4014 - accuracy: 0.3674\n",
      "Epoch 00047: val_loss did not improve from 2.75503\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 2.4014 - accuracy: 0.3674 - val_loss: 2.7693 - val_accuracy: 0.3016\n",
      "Epoch 48/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3871 - accuracy: 0.3692\n",
      "Epoch 00048: val_loss improved from 2.75503 to 2.75025, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.3871 - accuracy: 0.3692 - val_loss: 2.7502 - val_accuracy: 0.3060\n",
      "Epoch 49/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3726 - accuracy: 0.3719\n",
      "Epoch 00049: val_loss improved from 2.75025 to 2.74405, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 2.3726 - accuracy: 0.3719 - val_loss: 2.7441 - val_accuracy: 0.3081\n",
      "Epoch 50/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3598 - accuracy: 0.3749\n",
      "Epoch 00050: val_loss did not improve from 2.74405\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 2.3598 - accuracy: 0.3749 - val_loss: 2.7619 - val_accuracy: 0.3026\n",
      "Epoch 51/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3485 - accuracy: 0.3780\n",
      "Epoch 00051: val_loss improved from 2.74405 to 2.72437, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.3485 - accuracy: 0.3780 - val_loss: 2.7244 - val_accuracy: 0.3076\n",
      "Epoch 52/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3346 - accuracy: 0.3797\n",
      "Epoch 00052: val_loss did not improve from 2.72437\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.3346 - accuracy: 0.3797 - val_loss: 2.7427 - val_accuracy: 0.3061\n",
      "Epoch 53/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3200 - accuracy: 0.3828\n",
      "Epoch 00053: val_loss improved from 2.72437 to 2.72041, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.3200 - accuracy: 0.3828 - val_loss: 2.7204 - val_accuracy: 0.3120\n",
      "Epoch 54/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.3096 - accuracy: 0.3860\n",
      "Epoch 00054: val_loss improved from 2.72041 to 2.71953, saving model to InceptionV2_Adam_BatchNorm.h5\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 2.3096 - accuracy: 0.3860 - val_loss: 2.7195 - val_accuracy: 0.3151\n",
      "Epoch 55/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.2964 - accuracy: 0.3896\n",
      "Epoch 00055: val_loss did not improve from 2.71953\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.2964 - accuracy: 0.3896 - val_loss: 2.7375 - val_accuracy: 0.3104\n",
      "Epoch 56/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.2828 - accuracy: 0.3926\n",
      "Epoch 00056: val_loss did not improve from 2.71953\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.2828 - accuracy: 0.3926 - val_loss: 2.7222 - val_accuracy: 0.3155\n",
      "Epoch 57/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.2713 - accuracy: 0.3945\n",
      "Epoch 00057: val_loss did not improve from 2.71953\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.2713 - accuracy: 0.3945 - val_loss: 2.7329 - val_accuracy: 0.3106\n",
      "Epoch 58/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.2566 - accuracy: 0.3959\n",
      "Epoch 00058: val_loss did not improve from 2.71953\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.2566 - accuracy: 0.3959 - val_loss: 2.7245 - val_accuracy: 0.3136\n",
      "Epoch 59/150\n",
      "196/196 [==============================] - ETA: 0s - loss: 2.2476 - accuracy: 0.3998\n",
      "Epoch 00059: val_loss did not improve from 2.71953\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 2.2476 - accuracy: 0.3998 - val_loss: 2.7444 - val_accuracy: 0.3105\n",
      "Epoch 00059: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=150, batch_size=256, callbacks=[checkpoint,early])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0xFUMyq_tGF"
   },
   "source": [
    "<h3><b> Graphs</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "U4tGzn_O_n14",
    "outputId": "19eefee4-c8a1-4129-b2ae-16f18c1a2d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "accuracy_values = history_dict['accuracy']\n",
    "val_accuracy_values = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy_values, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "paDpykeG_pdP",
    "outputId": "1ef53867-9845-4ce1-e314-83c4644bc93f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2CBsx5a2h8O"
   },
   "source": [
    "<h3><b> Metric Calculation</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "XOhTm_r5_68l",
    "outputId": "e7240bb4-b6af-49da-9c64-f04361007c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.3024633366906804\n",
      "Recall: 0.3151\n",
      "Accuracy: 0.3151\n"
     ]
    }
   ],
   "source": [
    "model1 = Model(input_layer,  output)\n",
    "model1.load_weights(\"./InceptionV2_Adam_BatchNorm.h5\")\n",
    "#optimization details\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "lr_decay = 1e-6\n",
    "#optimization details\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "# Test the model\n",
    "model.predict(X_test).argmax(-1)\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(X_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_M6ri2847o1"
   },
   "source": [
    "<h3><b> References</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dF2G22fKjJEF"
   },
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/\n",
    "#https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionV2_Adam_BatchNorm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
