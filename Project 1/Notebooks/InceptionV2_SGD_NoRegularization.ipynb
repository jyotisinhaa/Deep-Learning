{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_SGD_NoRegularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyOazSpWztcP"
      },
      "source": [
        "<h3><b> Importing Library</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNYk17cCS0lA"
      },
      "source": [
        "# Importing Libraries\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import math \n",
        "import cv2 \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import regularizers\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D,Flatten"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3XLVJepz2DV"
      },
      "source": [
        "<h3><b> Importing Dataset</b><h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuhv097NYrfu",
        "outputId": "2d0c2aaa-8bce-4d86-bbab-4bf7eb6aaf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2yAtEqs0DTO"
      },
      "source": [
        "<h3><b> Preprocessing of the dataset</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1xMv3g8Yxl4"
      },
      "source": [
        "# Normalize the dataset\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUcSJ9bPY4Yu"
      },
      "source": [
        "#Converting the testing and training dataset into float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UfXOG68Y741",
        "outputId": "ebb61c4f-f5c3-4e39-ab6a-76db699aaba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert training and test labels to one hot matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_test = keras.utils.to_categorical(y_test, 100)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtqhVwFs0_yO"
      },
      "source": [
        "<h3><b> Model Architecure</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLLcjHtgid1I"
      },
      "source": [
        "def inception_moduleA(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_3x3a,\n",
        "                      filters_3x3b,\n",
        "                  \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='elu')(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3a = Conv2D(filters_3x3a, (3, 3), padding='same', activation='elu')(conv_5x5)\n",
        "    conv_3x3b = Conv2D(filters_3x3b, (3, 3), padding='same', activation='elu')(conv_3x3a)\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_3x3a, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def inception_moduleB(x,\n",
        "                     filters_1x1modb,\n",
        "                     filters_3x3_reducemodb,\n",
        "                     filters_1x3modb,\n",
        "                     filters_3x1modb,\n",
        "                     filters_5x5_reducemodb,\n",
        "                     filters_1x3amodb,\n",
        "                      filters_3x1amodb,\n",
        "                     filters_1x3bmodb,\n",
        "                      filters_3x1bmodb,\n",
        "                  \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1modb = Conv2D(filters_1x1modb, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3modb = Conv2D(filters_3x3_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3modb = Conv2D(filters_1x3modb, (1, 3), padding='same', activation='elu')(conv_3x3modb)\n",
        "    conv_3x1modb = Conv2D(filters_3x1modb, (3, 1), padding='same', activation='elu')(conv_1x3modb)\n",
        "\n",
        "    conv_5x5modb = Conv2D(filters_5x5_reducemodb, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3amodb = Conv2D(filters_1x3amodb, (1, 3), padding='same', activation='elu')(conv_5x5modb)\n",
        "    conv_3x1amodb = Conv2D(filters_3x1amodb, (3, 1), padding='same', activation='elu')(conv_1x3amodb)\n",
        "    conv_1x3bmodb = Conv2D(filters_1x3bmodb, (1, 3), padding='same', activation='elu')(conv_3x1amodb)\n",
        "    conv_3x1bmodb = Conv2D(filters_3x1bmodb, (3, 1), padding='same', activation='elu')(conv_1x3bmodb)\n",
        "\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1modb, conv_3x1modb, conv_3x1bmodb, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def inception_moduleC(x,\n",
        "                     filters_1x1modc,\n",
        "                      filters_3x3_reducemodc,\n",
        "                     filters_1x3modc,\n",
        "                      filters_3x1modc,\n",
        "                     filters_5x5_reducemodc,\n",
        "                        filters_3x3amodc,\n",
        "                      filters_1x3amodc,\n",
        "                       filters_3x1amodc,\n",
        "                      \n",
        "                   \n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1modc = Conv2D(filters_1x1modc, (1, 1), padding='same', activation='elu')(x)\n",
        "    \n",
        "    conv_3x3modc = Conv2D(filters_3x3_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_1x3modc = Conv2D(filters_1x3modc, (1, 3), padding='same', activation='elu')(conv_3x3modc)\n",
        "    conv_3x1modc = Conv2D(filters_3x1modc, (3, 1), padding='same', activation='elu')(conv_1x3modc)\n",
        "\n",
        "    conv_5x5modc = Conv2D(filters_5x5_reducemodc, (1, 1), padding='same', activation='elu')(x)\n",
        "    conv_3x3amodc = Conv2D(filters_3x3amodc, (1, 1), padding='same', activation='elu')(conv_5x5modc)\n",
        "\n",
        "    conv_1x3amodc = Conv2D(filters_1x3amodc, (1, 3), padding='same', activation='elu')(conv_3x3amodc)\n",
        "    conv_3x1amodc = Conv2D(filters_3x1amodc, (3, 1), padding='same', activation='elu')(conv_1x3amodc)\n",
        "\n",
        "\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='elu')(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1modc,conv_1x3modc, conv_3x1modc, conv_1x3amodc,conv_3x1amodc, pool_proj], axis=-1, name=name)\n",
        "    \n",
        "    return output\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br3rOWOzHxJJ"
      },
      "source": [
        "input_layer = Input(shape=(32, 32, 3))\n",
        "\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_1a_3x3/2')(input_layer)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_2a_3x3/1')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_3a_3x3/1')(x)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_4a_3x3/1')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(2, 2), activation='elu', name='conv_5a_3x3/2')(x)\n",
        "x = Conv2D(64, (3, 3), padding='same', strides=(1, 1), activation='elu', name='conv_6a_3x3/1')(x)\n",
        "\n",
        "x = inception_moduleA(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_3x3a=32,\n",
        "                     filters_3x3b=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3a')\n",
        "x = inception_moduleA(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_3x3a=32,\n",
        "                     filters_3x3b=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3aa')\n",
        "\n",
        "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
        "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
        "# x = inception_moduleA(x,\n",
        "#                      filters_1x1=64,\n",
        "#                      filters_3x3_reduce=96,\n",
        "#                      filters_3x3=128,\n",
        "#                      filters_5x5_reduce=16,\n",
        "#                      filters_3x3a=32,\n",
        "#                      filters_3x3b=32,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_3aaa')\n",
        "\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                   filters_pool_proj=32,\n",
        "                     name='inception_4a')\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_4aa')\n",
        "x = inception_moduleB(x,\n",
        "                     filters_1x1modb=64,\n",
        "                     filters_3x3_reducemodb=96,\n",
        "                     filters_1x3modb=128,\n",
        "                     filters_3x1modb=128,\n",
        "                     filters_5x5_reducemodb=16,\n",
        "                     filters_1x3amodb=128,\n",
        "                     filters_3x1amodb=128,\n",
        "                     filters_1x3bmodb=128,\n",
        "                     filters_3x1bmodb=128,\n",
        "                      filters_pool_proj=32,\n",
        "             \n",
        "                     name='inception_4aaa')\n",
        "#I am commenting the numbers of times module A, ModuleB is called as it is helping to increase my accuracy.In original InceptionV2 architecture ModuleA is called\n",
        "#3 times, ModuleB is called 5 times and ModuleC is called 2 times:-\n",
        "# x = inception_moduleB(x,\n",
        "#                      filters_1x1modb=64,\n",
        "#                      filters_3x3_reducemodb=96,\n",
        "#                      filters_1x3modb=128,\n",
        "#                      filters_3x1modb=128,\n",
        "#                      filters_5x5_reducemodb=16,\n",
        "#                      filters_1x3amodb=128,\n",
        "#                      filters_3x1amodb=128,\n",
        "#                      filters_1x3bmodb=128,\n",
        "#                      filters_3x1bmodb=128,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_4aaaa')\n",
        "# x = inception_moduleB(x,\n",
        "#                      filters_1x1modb=64,\n",
        "#                      filters_3x3_reducemodb=96,\n",
        "#                      filters_1x3modb=128,\n",
        "#                      filters_3x1modb=128,\n",
        "#                      filters_5x5_reducemodb=16,\n",
        "#                      filters_1x3amodb=128,\n",
        "#                      filters_3x1amodb=128,\n",
        "#                      filters_1x3bmodb=128,\n",
        "#                      filters_3x1bmodb=128,\n",
        "#                      filters_pool_proj=32,\n",
        "#                      name='inception_4aaaaa')\n",
        "\n",
        "x = inception_moduleC(x,\n",
        "                     filters_1x1modc=64,\n",
        "                     filters_3x3_reducemodc=96,\n",
        "                     filters_1x3modc=128,\n",
        "                     filters_3x1modc=128,\n",
        "                     filters_5x5_reducemodc=16,\n",
        "                     filters_3x3amodc=128,\n",
        "                     filters_1x3amodc=128,\n",
        "                     filters_3x1amodc=128,\n",
        "                     filters_pool_proj=32,\n",
        "                    \n",
        "                     name='inception_5a')\n",
        "x = inception_moduleC(x,\n",
        "                     filters_1x1modc=64,\n",
        "                     filters_3x3_reducemodc=96,\n",
        "                     filters_1x3modc=128,\n",
        "                     filters_3x1modc=128,\n",
        "                     filters_5x5_reducemodc=16,\n",
        "                     filters_3x3amodc=128,\n",
        "                     filters_1x3amodc=128,\n",
        "                     filters_3x1amodc=128,\n",
        "                     filters_pool_proj=32,\n",
        "             \n",
        "                     name='inception_5aa')\n",
        "\n",
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "# x = Dropout(0.4)(x)\n",
        "x = Flatten()(x)\n",
        "output = Dense(100, activation='softmax', name='output')(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GWOmOi_qTCS"
      },
      "source": [
        "model = Model(input_layer,  output)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok_nFUWbFuwg",
        "outputId": "a32d29aa-61f6-469f-99e0-191c1345fb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1a_3x3/2 (Conv2D)          (None, 16, 16, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_2a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       conv_1a_3x3/2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_3a_3x3/1 (Conv2D)          (None, 16, 16, 64)   36928       conv_2a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_3x3/2 (MaxPooling2D) (None, 8, 8, 64)     0           conv_3a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_4a_3x3/1 (Conv2D)          (None, 8, 8, 64)     36928       max_pool_2_3x3/2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv_5a_3x3/2 (Conv2D)          (None, 4, 4, 64)     36928       conv_4a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv_6a_3x3/1 (Conv2D)          (None, 4, 4, 64)     36928       conv_5a_3x3/2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 4, 4, 96)     6240        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 16)     1040        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 4, 4, 64)     0           conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 4, 4, 64)     4160        conv_6a_3x3/1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 4, 4, 128)    110720      conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 4, 4, 32)     4640        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 4, 4, 32)     2080        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a (Concatenate)      (None, 4, 4, 256)    0           conv2d[0][0]                     \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 4, 4, 96)     24672       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 16)     4112        inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 256)    0           inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 64)     16448       inception_3a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 128)    110720      conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 4, 4, 32)     4640        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 4, 4, 32)     8224        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3aa (Concatenate)     (None, 4, 4, 256)    0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 16)     4112        inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 96)     24672       inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 256)    0           inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 64)     16448       inception_3aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 32)     8224        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a (Concatenate)      (None, 4, 4, 352)    0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 16)     5648        inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 96)     33888       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 64)     22592       inception_4a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4aa (Concatenate)     (None, 4, 4, 352)    0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "                                                                 conv2d_32[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 16)     5648        inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 128)    6272        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 96)     33888       inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 64)     22592       inception_4aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_4aaa (Concatenate)    (None, 4, 4, 352)    0           conv2d_34[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 16)     5648        inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 96)     33888       inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 128)    2176        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 352)    0           inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 64)     22592       inception_4aaa[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 32)     11296       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a (Concatenate)      (None, 4, 4, 608)    0           conv2d_44[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "                                                                 conv2d_47[0][0]                  \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "                                                                 conv2d_51[0][0]                  \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 4, 4, 16)     9744        inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 4, 4, 96)     58464       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 4, 4, 128)    2176        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 4, 4, 128)    36992       conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 608)    0           inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 4, 4, 64)     38976       inception_5a[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 4, 4, 128)    49280       conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 4, 4, 32)     19488       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5aa (Concatenate)     (None, 4, 4, 608)    0           conv2d_53[0][0]                  \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "                                                                 conv2d_59[0][0]                  \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool_5_3x3/1 (GlobalAverage (None, 608)          0           inception_5aa[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 608)          0           avg_pool_5_3x3/1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 100)          60900       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,040,596\n",
            "Trainable params: 2,040,596\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-jkzpVu1SSF"
      },
      "source": [
        "<h3><b> Model Compile</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPd9gc_sBziE"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "lr_decay = 1e-6\n",
        "#optimization details\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_rq-y4K1rgo",
        "outputId": "908257af-7eae-4b84-b8a8-ea9bb19dadf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create Checkpoint and Early Stopping\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"InceptionV2_SGD_NoRegularization.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HogWDFCh1ZxX"
      },
      "source": [
        "<h3><b> Train the Model</b><h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxkeVrtvF0Ok",
        "outputId": "532cc016-3e44-4cba-a33d-d865bcded13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=150, batch_size=256, callbacks=[checkpoint,early])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.6049 - accuracy: 0.0079\n",
            "Epoch 00001: val_loss improved from inf to 4.60254, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 11s 57ms/step - loss: 4.6049 - accuracy: 0.0079 - val_loss: 4.6025 - val_accuracy: 0.0090\n",
            "Epoch 2/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.6004 - accuracy: 0.0123\n",
            "Epoch 00002: val_loss improved from 4.60254 to 4.59764, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.6004 - accuracy: 0.0123 - val_loss: 4.5976 - val_accuracy: 0.0145\n",
            "Epoch 3/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.5920 - accuracy: 0.0189\n",
            "Epoch 00003: val_loss improved from 4.59764 to 4.58298, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.5920 - accuracy: 0.0189 - val_loss: 4.5830 - val_accuracy: 0.0225\n",
            "Epoch 4/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.5483 - accuracy: 0.0262\n",
            "Epoch 00004: val_loss improved from 4.58298 to 4.49241, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 53ms/step - loss: 4.5482 - accuracy: 0.0262 - val_loss: 4.4924 - val_accuracy: 0.0258\n",
            "Epoch 5/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.4411 - accuracy: 0.0259\n",
            "Epoch 00005: val_loss improved from 4.49241 to 4.39997, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 53ms/step - loss: 4.4411 - accuracy: 0.0258 - val_loss: 4.4000 - val_accuracy: 0.0244\n",
            "Epoch 6/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.3621 - accuracy: 0.0284\n",
            "Epoch 00006: val_loss improved from 4.39997 to 4.33007, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.3621 - accuracy: 0.0284 - val_loss: 4.3301 - val_accuracy: 0.0319\n",
            "Epoch 7/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.2821 - accuracy: 0.0381\n",
            "Epoch 00007: val_loss improved from 4.33007 to 4.25923, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.2821 - accuracy: 0.0381 - val_loss: 4.2592 - val_accuracy: 0.0437\n",
            "Epoch 8/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.2013 - accuracy: 0.0515\n",
            "Epoch 00008: val_loss improved from 4.25923 to 4.17235, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.2013 - accuracy: 0.0515 - val_loss: 4.1724 - val_accuracy: 0.0554\n",
            "Epoch 9/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 4.1347 - accuracy: 0.0593\n",
            "Epoch 00009: val_loss improved from 4.17235 to 4.10758, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 51ms/step - loss: 4.1347 - accuracy: 0.0593 - val_loss: 4.1076 - val_accuracy: 0.0666\n",
            "Epoch 10/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.0804 - accuracy: 0.0677\n",
            "Epoch 00010: val_loss improved from 4.10758 to 4.06408, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.0803 - accuracy: 0.0677 - val_loss: 4.0641 - val_accuracy: 0.0734\n",
            "Epoch 11/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 4.0116 - accuracy: 0.0797\n",
            "Epoch 00011: val_loss improved from 4.06408 to 3.97489, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 4.0116 - accuracy: 0.0797 - val_loss: 3.9749 - val_accuracy: 0.0872\n",
            "Epoch 12/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.9215 - accuracy: 0.0912\n",
            "Epoch 00012: val_loss improved from 3.97489 to 3.91247, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.9215 - accuracy: 0.0912 - val_loss: 3.9125 - val_accuracy: 0.0906\n",
            "Epoch 13/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.8280 - accuracy: 0.1043\n",
            "Epoch 00013: val_loss improved from 3.91247 to 3.83015, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.8280 - accuracy: 0.1043 - val_loss: 3.8302 - val_accuracy: 0.1060\n",
            "Epoch 14/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.7594 - accuracy: 0.1154\n",
            "Epoch 00014: val_loss improved from 3.83015 to 3.74090, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.7594 - accuracy: 0.1154 - val_loss: 3.7409 - val_accuracy: 0.1162\n",
            "Epoch 15/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.7050 - accuracy: 0.1211\n",
            "Epoch 00015: val_loss improved from 3.74090 to 3.68698, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.7051 - accuracy: 0.1212 - val_loss: 3.6870 - val_accuracy: 0.1243\n",
            "Epoch 16/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.6598 - accuracy: 0.1294\n",
            "Epoch 00016: val_loss did not improve from 3.68698\n",
            "196/196 [==============================] - 10s 51ms/step - loss: 3.6598 - accuracy: 0.1294 - val_loss: 3.6995 - val_accuracy: 0.1251\n",
            "Epoch 17/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.6159 - accuracy: 0.1342\n",
            "Epoch 00017: val_loss improved from 3.68698 to 3.61624, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.6159 - accuracy: 0.1342 - val_loss: 3.6162 - val_accuracy: 0.1316\n",
            "Epoch 18/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.5653 - accuracy: 0.1403\n",
            "Epoch 00018: val_loss improved from 3.61624 to 3.57405, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.5652 - accuracy: 0.1404 - val_loss: 3.5740 - val_accuracy: 0.1433\n",
            "Epoch 19/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.5110 - accuracy: 0.1506\n",
            "Epoch 00019: val_loss did not improve from 3.57405\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.5110 - accuracy: 0.1506 - val_loss: 3.6285 - val_accuracy: 0.1309\n",
            "Epoch 20/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.4559 - accuracy: 0.1587\n",
            "Epoch 00020: val_loss improved from 3.57405 to 3.47860, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.4560 - accuracy: 0.1586 - val_loss: 3.4786 - val_accuracy: 0.1562\n",
            "Epoch 21/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.4055 - accuracy: 0.1661\n",
            "Epoch 00021: val_loss improved from 3.47860 to 3.40553, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.4054 - accuracy: 0.1661 - val_loss: 3.4055 - val_accuracy: 0.1726\n",
            "Epoch 22/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.3491 - accuracy: 0.1762\n",
            "Epoch 00022: val_loss improved from 3.40553 to 3.34230, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 53ms/step - loss: 3.3491 - accuracy: 0.1762 - val_loss: 3.3423 - val_accuracy: 0.1815\n",
            "Epoch 23/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.2956 - accuracy: 0.1858\n",
            "Epoch 00023: val_loss improved from 3.34230 to 3.34163, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.2955 - accuracy: 0.1858 - val_loss: 3.3416 - val_accuracy: 0.1801\n",
            "Epoch 24/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.2463 - accuracy: 0.1921\n",
            "Epoch 00024: val_loss improved from 3.34163 to 3.26303, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.2463 - accuracy: 0.1921 - val_loss: 3.2630 - val_accuracy: 0.1953\n",
            "Epoch 25/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 3.1980 - accuracy: 0.2031\n",
            "Epoch 00025: val_loss improved from 3.26303 to 3.22700, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.1980 - accuracy: 0.2031 - val_loss: 3.2270 - val_accuracy: 0.2056\n",
            "Epoch 26/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.1526 - accuracy: 0.2129\n",
            "Epoch 00026: val_loss improved from 3.22700 to 3.19467, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.1522 - accuracy: 0.2130 - val_loss: 3.1947 - val_accuracy: 0.2048\n",
            "Epoch 27/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.1037 - accuracy: 0.2202\n",
            "Epoch 00027: val_loss improved from 3.19467 to 3.13274, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.1041 - accuracy: 0.2201 - val_loss: 3.1327 - val_accuracy: 0.2222\n",
            "Epoch 28/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.0570 - accuracy: 0.2311\n",
            "Epoch 00028: val_loss improved from 3.13274 to 3.10628, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.0568 - accuracy: 0.2311 - val_loss: 3.1063 - val_accuracy: 0.2313\n",
            "Epoch 29/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 3.0053 - accuracy: 0.2410\n",
            "Epoch 00029: val_loss improved from 3.10628 to 3.08328, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 3.0054 - accuracy: 0.2409 - val_loss: 3.0833 - val_accuracy: 0.2317\n",
            "Epoch 30/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.9562 - accuracy: 0.2511\n",
            "Epoch 00030: val_loss improved from 3.08328 to 3.04401, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.9564 - accuracy: 0.2510 - val_loss: 3.0440 - val_accuracy: 0.2424\n",
            "Epoch 31/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.9058 - accuracy: 0.2602\n",
            "Epoch 00031: val_loss improved from 3.04401 to 3.01234, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.9057 - accuracy: 0.2602 - val_loss: 3.0123 - val_accuracy: 0.2466\n",
            "Epoch 32/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.8600 - accuracy: 0.2680\n",
            "Epoch 00032: val_loss improved from 3.01234 to 2.96260, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.8602 - accuracy: 0.2679 - val_loss: 2.9626 - val_accuracy: 0.2554\n",
            "Epoch 33/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.8183 - accuracy: 0.2763\n",
            "Epoch 00033: val_loss improved from 2.96260 to 2.93606, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.8183 - accuracy: 0.2763 - val_loss: 2.9361 - val_accuracy: 0.2606\n",
            "Epoch 34/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.7786 - accuracy: 0.2862\n",
            "Epoch 00034: val_loss improved from 2.93606 to 2.87855, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.7789 - accuracy: 0.2862 - val_loss: 2.8786 - val_accuracy: 0.2708\n",
            "Epoch 35/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.7348 - accuracy: 0.2955\n",
            "Epoch 00035: val_loss improved from 2.87855 to 2.87291, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.7345 - accuracy: 0.2956 - val_loss: 2.8729 - val_accuracy: 0.2719\n",
            "Epoch 36/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.6924 - accuracy: 0.3015\n",
            "Epoch 00036: val_loss improved from 2.87291 to 2.84452, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.6924 - accuracy: 0.3015 - val_loss: 2.8445 - val_accuracy: 0.2741\n",
            "Epoch 37/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.6567 - accuracy: 0.3100\n",
            "Epoch 00037: val_loss improved from 2.84452 to 2.80811, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.6567 - accuracy: 0.3100 - val_loss: 2.8081 - val_accuracy: 0.2888\n",
            "Epoch 38/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.6196 - accuracy: 0.3173\n",
            "Epoch 00038: val_loss improved from 2.80811 to 2.79559, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.6192 - accuracy: 0.3174 - val_loss: 2.7956 - val_accuracy: 0.2906\n",
            "Epoch 39/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.5833 - accuracy: 0.3262\n",
            "Epoch 00039: val_loss did not improve from 2.79559\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.5833 - accuracy: 0.3262 - val_loss: 2.7991 - val_accuracy: 0.2926\n",
            "Epoch 40/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.5522 - accuracy: 0.3327\n",
            "Epoch 00040: val_loss improved from 2.79559 to 2.72100, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.5515 - accuracy: 0.3328 - val_loss: 2.7210 - val_accuracy: 0.3074\n",
            "Epoch 41/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.5137 - accuracy: 0.3396\n",
            "Epoch 00041: val_loss improved from 2.72100 to 2.71275, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.5140 - accuracy: 0.3396 - val_loss: 2.7127 - val_accuracy: 0.3096\n",
            "Epoch 42/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4808 - accuracy: 0.3465\n",
            "Epoch 00042: val_loss did not improve from 2.71275\n",
            "196/196 [==============================] - 10s 51ms/step - loss: 2.4808 - accuracy: 0.3465 - val_loss: 2.7697 - val_accuracy: 0.3054\n",
            "Epoch 43/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.4478 - accuracy: 0.3538\n",
            "Epoch 00043: val_loss improved from 2.71275 to 2.71192, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.4479 - accuracy: 0.3537 - val_loss: 2.7119 - val_accuracy: 0.3167\n",
            "Epoch 44/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.4142 - accuracy: 0.3615\n",
            "Epoch 00044: val_loss did not improve from 2.71192\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.4142 - accuracy: 0.3615 - val_loss: 2.7175 - val_accuracy: 0.3102\n",
            "Epoch 45/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.3821 - accuracy: 0.3657\n",
            "Epoch 00045: val_loss improved from 2.71192 to 2.67020, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.3825 - accuracy: 0.3656 - val_loss: 2.6702 - val_accuracy: 0.3192\n",
            "Epoch 46/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.3439 - accuracy: 0.3742\n",
            "Epoch 00046: val_loss improved from 2.67020 to 2.63649, saving model to InceptionV2_SGD_NoRegularization.h5\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.3439 - accuracy: 0.3742 - val_loss: 2.6365 - val_accuracy: 0.3258\n",
            "Epoch 47/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.3158 - accuracy: 0.3800\n",
            "Epoch 00047: val_loss did not improve from 2.63649\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.3155 - accuracy: 0.3801 - val_loss: 2.6460 - val_accuracy: 0.3233\n",
            "Epoch 48/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.2830 - accuracy: 0.3866\n",
            "Epoch 00048: val_loss did not improve from 2.63649\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.2833 - accuracy: 0.3864 - val_loss: 2.6533 - val_accuracy: 0.3270\n",
            "Epoch 49/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.2548 - accuracy: 0.3927\n",
            "Epoch 00049: val_loss did not improve from 2.63649\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.2550 - accuracy: 0.3927 - val_loss: 2.6731 - val_accuracy: 0.3198\n",
            "Epoch 50/150\n",
            "195/196 [============================>.] - ETA: 0s - loss: 2.2225 - accuracy: 0.4002\n",
            "Epoch 00050: val_loss did not improve from 2.63649\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.2228 - accuracy: 0.4002 - val_loss: 2.7499 - val_accuracy: 0.3135\n",
            "Epoch 51/150\n",
            "196/196 [==============================] - ETA: 0s - loss: 2.1915 - accuracy: 0.4084\n",
            "Epoch 00051: val_loss did not improve from 2.63649\n",
            "196/196 [==============================] - 10s 52ms/step - loss: 2.1915 - accuracy: 0.4084 - val_loss: 2.6529 - val_accuracy: 0.3357\n",
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0xFUMyq_tGF"
      },
      "source": [
        "<h3><b> Graphs</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4tGzn_O_n14",
        "outputId": "ba36af98-5b69-471c-c19c-2b4bbf08aa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "accuracy_values = history_dict['accuracy']\n",
        "val_accuracy_values = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, accuracy_values, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paDpykeG_pdP",
        "outputId": "206ea5a7-08ef-4995-9f27-8582984c4915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "print(history_dict.keys())\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2CBsx5a2h8O"
      },
      "source": [
        "<h3><b> Metric Calculation</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOhTm_r5_68l",
        "outputId": "6b7180d5-ad31-47ee-c842-4668ac885cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model1 = Model(input_layer,  output)\n",
        "model1.load_weights(\"./InceptionV2_SGD_NoRegularization.h5\")\n",
        "#optimization details\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "lr_decay = 1e-6\n",
        "#optimization details\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "# Test the model\n",
        "model.predict(X_test).argmax(-1)\n",
        "\n",
        "y_true = y_test.argmax(-1)\n",
        "y_pred = model.predict(X_test).argmax(-1)\n",
        "# generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "confusion_matrix(y_true, y_pred)\n",
        "# calculate prec, recall, accuracy\n",
        "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prec: 0.32165669292916405\n",
            "Recall: 0.3258\n",
            "Accuracy: 0.3258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_M6ri2847o1"
      },
      "source": [
        "<h3><b> References</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2G22fKjJEF"
      },
      "source": [
        "#https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/\n",
        "#https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}